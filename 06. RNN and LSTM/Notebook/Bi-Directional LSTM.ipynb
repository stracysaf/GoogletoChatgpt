{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"OZx4eZ2CaOmJ","executionInfo":{"status":"ok","timestamp":1712319553030,"user_tz":-330,"elapsed":3515,"user":{"displayName":"jiyaudeen Meerasa","userId":"17480471567784096893"}}},"outputs":[],"source":["import numpy as np\n","\n","from sklearn.metrics import accuracy_score\n","from keras.datasets import reuters\n","from keras.preprocessing.sequence import pad_sequences\n","from keras.utils import to_categorical\n","from keras.models import Sequential\n","from keras.layers import Dense, LSTM, Activation, GRU\n","from keras import optimizers\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JQC7wlVtaOmL"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":2,"metadata":{"collapsed":true,"jupyter":{"outputs_hidden":true},"id":"JRy99SmAaOmL","executionInfo":{"status":"ok","timestamp":1712319558654,"user_tz":-330,"elapsed":1280,"user":{"displayName":"jiyaudeen Meerasa","userId":"17480471567784096893"}}},"outputs":[],"source":["# parameters for data load\n","num_words = 30000\n","maxlen = 50\n","test_split = 0.3"]},{"cell_type":"code","execution_count":3,"metadata":{"collapsed":true,"jupyter":{"outputs_hidden":true},"id":"cKty8WyZaOmL","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1712319563332,"user_tz":-330,"elapsed":4,"user":{"displayName":"jiyaudeen Meerasa","userId":"17480471567784096893"}},"outputId":"fdd4f3c7-2eca-41a6-efca-58b127fe6b73"},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/reuters.npz\n","2110848/2110848 [==============================] - 0s 0us/step\n"]}],"source":["(X_train, y_train), (X_test, y_test) = reuters.load_data(num_words = num_words, maxlen = maxlen, test_split = test_split)"]},{"cell_type":"code","execution_count":4,"metadata":{"collapsed":true,"jupyter":{"outputs_hidden":true},"id":"KY0unKBHaOmL","executionInfo":{"status":"ok","timestamp":1712319571010,"user_tz":-330,"elapsed":589,"user":{"displayName":"jiyaudeen Meerasa","userId":"17480471567784096893"}}},"outputs":[],"source":["# pad the sequences with zeros\n","# padding parameter is set to 'post' => 0's are appended to end of sequences\n","X_train = pad_sequences(X_train, padding = 'post')\n","X_test = pad_sequences(X_test, padding = 'post')\n","\n","X_train = np.array(X_train).reshape((X_train.shape[0], X_train.shape[1], 1))\n","X_test = np.array(X_test).reshape((X_test.shape[0], X_test.shape[1], 1))\n","\n","y_data = np.concatenate((y_train, y_test))\n","y_data = to_categorical(y_data)\n","\n","y_actual = y_test\n","\n","y_train = y_data[:1395]\n","y_test = y_data[1395:]"]},{"cell_type":"code","source":["X_train.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qQ6BzZNuLSkl","executionInfo":{"status":"ok","timestamp":1712319575428,"user_tz":-330,"elapsed":630,"user":{"displayName":"jiyaudeen Meerasa","userId":"17480471567784096893"}},"outputId":"4ab0714b-1093-4e4a-baba-5d536c3b4edc"},"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(1395, 49, 1)"]},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":["y_data.shape"],"metadata":{"id":"sRUQa3azSWzT","executionInfo":{"status":"ok","timestamp":1712319580334,"user_tz":-330,"elapsed":467,"user":{"displayName":"jiyaudeen Meerasa","userId":"17480471567784096893"}},"outputId":"d6040fca-e4b7-427e-eb02-ceceef91b00d","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(1994, 46)"]},"metadata":{},"execution_count":6}]},{"cell_type":"markdown","metadata":{"id":"q9krpUWJaOmL"},"source":["## 1. Deep LSTM\n","- LSTMs can be made deep, with multiple layers, like CNNs or MLPs\n","- Beware that LSTMs take long to train compared to CNNs"]},{"cell_type":"code","execution_count":7,"metadata":{"collapsed":true,"jupyter":{"outputs_hidden":true},"id":"H8-t2aKHaOmT","executionInfo":{"status":"ok","timestamp":1712319584116,"user_tz":-330,"elapsed":484,"user":{"displayName":"jiyaudeen Meerasa","userId":"17480471567784096893"}}},"outputs":[],"source":["from keras.models import Sequential\n","from keras.layers import Dense, LSTM, Activation, GRU\n","from keras import optimizers\n"]},{"cell_type":"code","execution_count":8,"metadata":{"collapsed":true,"jupyter":{"outputs_hidden":true},"id":"PFMFzLJ_aOmT","executionInfo":{"status":"ok","timestamp":1712319586237,"user_tz":-330,"elapsed":392,"user":{"displayName":"jiyaudeen Meerasa","userId":"17480471567784096893"}}},"outputs":[],"source":["def deep_lstm():\n","    model = Sequential()\n","    model.add(LSTM(20, input_shape = (49,1), return_sequences = True))\n","    model.add(LSTM(20, return_sequences = True))\n","    model.add(LSTM(20, return_sequences = True))\n","    model.add(LSTM(20, return_sequences = False))\n","    model.add(Dense(46))\n","    model.add(Activation('softmax'))\n","\n","    adam = optimizers.Adam(lr = 0.001)\n","    model.compile(loss = 'categorical_crossentropy', optimizer = adam, metrics = ['accuracy'])\n","\n","    return model"]},{"cell_type":"code","execution_count":9,"metadata":{"collapsed":true,"jupyter":{"outputs_hidden":true},"colab":{"base_uri":"https://localhost:8080/"},"id":"shKopDP_aOmT","outputId":"dd1c9ea4-47a1-4f7a-cac4-9d3d5649d549","executionInfo":{"status":"ok","timestamp":1712319681188,"user_tz":-330,"elapsed":92734,"user":{"displayName":"jiyaudeen Meerasa","userId":"17480471567784096893"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/200\n","28/28 [==============================] - 8s 17ms/step - loss: 3.3088 - accuracy: 0.6573\n","Epoch 2/200\n","28/28 [==============================] - 0s 16ms/step - loss: 2.0167 - accuracy: 0.7147\n","Epoch 3/200\n","28/28 [==============================] - 0s 16ms/step - loss: 1.3961 - accuracy: 0.7147\n","Epoch 4/200\n","28/28 [==============================] - 0s 18ms/step - loss: 1.2565 - accuracy: 0.7147\n","Epoch 5/200\n","28/28 [==============================] - 0s 17ms/step - loss: 1.2118 - accuracy: 0.7147\n","Epoch 6/200\n","28/28 [==============================] - 0s 13ms/step - loss: 1.1910 - accuracy: 0.7147\n","Epoch 7/200\n","28/28 [==============================] - 0s 12ms/step - loss: 1.1797 - accuracy: 0.7147\n","Epoch 8/200\n","28/28 [==============================] - 0s 12ms/step - loss: 1.1741 - accuracy: 0.7147\n","Epoch 9/200\n","28/28 [==============================] - 0s 13ms/step - loss: 1.1693 - accuracy: 0.7147\n","Epoch 10/200\n","28/28 [==============================] - 0s 12ms/step - loss: 1.1666 - accuracy: 0.7147\n","Epoch 11/200\n","28/28 [==============================] - 0s 13ms/step - loss: 1.1641 - accuracy: 0.7147\n","Epoch 12/200\n","28/28 [==============================] - 0s 12ms/step - loss: 1.1625 - accuracy: 0.7147\n","Epoch 13/200\n","28/28 [==============================] - 0s 13ms/step - loss: 1.1611 - accuracy: 0.7147\n","Epoch 14/200\n","28/28 [==============================] - 0s 12ms/step - loss: 1.1603 - accuracy: 0.7147\n","Epoch 15/200\n","28/28 [==============================] - 0s 12ms/step - loss: 1.1609 - accuracy: 0.7147\n","Epoch 16/200\n","28/28 [==============================] - 0s 12ms/step - loss: 1.1588 - accuracy: 0.7147\n","Epoch 17/200\n","28/28 [==============================] - 0s 12ms/step - loss: 1.1584 - accuracy: 0.7147\n","Epoch 18/200\n","28/28 [==============================] - 0s 12ms/step - loss: 1.1580 - accuracy: 0.7147\n","Epoch 19/200\n","28/28 [==============================] - 0s 12ms/step - loss: 1.1574 - accuracy: 0.7147\n","Epoch 20/200\n","28/28 [==============================] - 0s 12ms/step - loss: 1.1578 - accuracy: 0.7147\n","Epoch 21/200\n","28/28 [==============================] - 0s 13ms/step - loss: 1.1569 - accuracy: 0.7147\n","Epoch 22/200\n","28/28 [==============================] - 0s 12ms/step - loss: 1.1564 - accuracy: 0.7147\n","Epoch 23/200\n","28/28 [==============================] - 0s 13ms/step - loss: 1.1567 - accuracy: 0.7147\n","Epoch 24/200\n","28/28 [==============================] - 0s 12ms/step - loss: 1.1559 - accuracy: 0.7147\n","Epoch 25/200\n","28/28 [==============================] - 0s 12ms/step - loss: 1.1556 - accuracy: 0.7147\n","Epoch 26/200\n","28/28 [==============================] - 0s 12ms/step - loss: 1.1536 - accuracy: 0.7147\n","Epoch 27/200\n","28/28 [==============================] - 0s 13ms/step - loss: 1.1438 - accuracy: 0.7147\n","Epoch 28/200\n","28/28 [==============================] - 0s 12ms/step - loss: 1.1356 - accuracy: 0.7147\n","Epoch 29/200\n","28/28 [==============================] - 0s 12ms/step - loss: 1.1254 - accuracy: 0.7147\n","Epoch 30/200\n","28/28 [==============================] - 0s 13ms/step - loss: 1.1191 - accuracy: 0.7147\n","Epoch 31/200\n","28/28 [==============================] - 0s 12ms/step - loss: 1.1091 - accuracy: 0.7147\n","Epoch 32/200\n","28/28 [==============================] - 0s 12ms/step - loss: 1.1008 - accuracy: 0.7147\n","Epoch 33/200\n","28/28 [==============================] - 0s 13ms/step - loss: 1.0706 - accuracy: 0.7147\n","Epoch 34/200\n","28/28 [==============================] - 0s 16ms/step - loss: 0.9755 - accuracy: 0.7326\n","Epoch 35/200\n","28/28 [==============================] - 1s 18ms/step - loss: 0.9474 - accuracy: 0.7556\n","Epoch 36/200\n","28/28 [==============================] - 0s 17ms/step - loss: 0.9162 - accuracy: 0.7742\n","Epoch 37/200\n","28/28 [==============================] - 1s 18ms/step - loss: 0.8594 - accuracy: 0.7950\n","Epoch 38/200\n","28/28 [==============================] - 0s 14ms/step - loss: 0.8535 - accuracy: 0.7907\n","Epoch 39/200\n","28/28 [==============================] - 0s 12ms/step - loss: 0.8560 - accuracy: 0.7921\n","Epoch 40/200\n","28/28 [==============================] - 0s 13ms/step - loss: 0.8674 - accuracy: 0.7907\n","Epoch 41/200\n","28/28 [==============================] - 0s 12ms/step - loss: 0.8335 - accuracy: 0.8007\n","Epoch 42/200\n","28/28 [==============================] - 0s 12ms/step - loss: 0.8160 - accuracy: 0.8108\n","Epoch 43/200\n","28/28 [==============================] - 0s 12ms/step - loss: 0.7996 - accuracy: 0.8208\n","Epoch 44/200\n","28/28 [==============================] - 0s 12ms/step - loss: 0.8170 - accuracy: 0.8151\n","Epoch 45/200\n","28/28 [==============================] - 0s 13ms/step - loss: 0.7953 - accuracy: 0.8143\n","Epoch 46/200\n","28/28 [==============================] - 0s 13ms/step - loss: 0.8093 - accuracy: 0.8065\n","Epoch 47/200\n","28/28 [==============================] - 0s 12ms/step - loss: 0.8073 - accuracy: 0.8100\n","Epoch 48/200\n","28/28 [==============================] - 0s 13ms/step - loss: 0.7777 - accuracy: 0.8222\n","Epoch 49/200\n","28/28 [==============================] - 0s 13ms/step - loss: 0.7683 - accuracy: 0.8222\n","Epoch 50/200\n","28/28 [==============================] - 0s 12ms/step - loss: 0.7643 - accuracy: 0.8179\n","Epoch 51/200\n","28/28 [==============================] - 0s 14ms/step - loss: 0.7566 - accuracy: 0.8244\n","Epoch 52/200\n","28/28 [==============================] - 0s 12ms/step - loss: 0.7914 - accuracy: 0.8100\n","Epoch 53/200\n","28/28 [==============================] - 0s 13ms/step - loss: 0.7577 - accuracy: 0.8158\n","Epoch 54/200\n","28/28 [==============================] - 0s 12ms/step - loss: 0.7791 - accuracy: 0.8122\n","Epoch 55/200\n","28/28 [==============================] - 0s 12ms/step - loss: 0.7421 - accuracy: 0.8229\n","Epoch 56/200\n","28/28 [==============================] - 0s 12ms/step - loss: 0.7441 - accuracy: 0.8208\n","Epoch 57/200\n","28/28 [==============================] - 0s 13ms/step - loss: 0.7515 - accuracy: 0.8186\n","Epoch 58/200\n","28/28 [==============================] - 0s 12ms/step - loss: 0.7338 - accuracy: 0.8194\n","Epoch 59/200\n","28/28 [==============================] - 0s 12ms/step - loss: 0.7419 - accuracy: 0.8172\n","Epoch 60/200\n","28/28 [==============================] - 0s 13ms/step - loss: 0.7874 - accuracy: 0.8086\n","Epoch 61/200\n","28/28 [==============================] - 0s 12ms/step - loss: 0.7340 - accuracy: 0.8201\n","Epoch 62/200\n","28/28 [==============================] - 0s 13ms/step - loss: 0.7162 - accuracy: 0.8229\n","Epoch 63/200\n","28/28 [==============================] - 0s 13ms/step - loss: 0.7231 - accuracy: 0.8301\n","Epoch 64/200\n","28/28 [==============================] - 0s 12ms/step - loss: 0.7156 - accuracy: 0.8416\n","Epoch 65/200\n","28/28 [==============================] - 0s 13ms/step - loss: 0.7020 - accuracy: 0.8452\n","Epoch 66/200\n","28/28 [==============================] - 0s 17ms/step - loss: 0.7259 - accuracy: 0.8394\n","Epoch 67/200\n","28/28 [==============================] - 0s 16ms/step - loss: 0.7173 - accuracy: 0.8330\n","Epoch 68/200\n","28/28 [==============================] - 0s 17ms/step - loss: 0.7128 - accuracy: 0.8394\n","Epoch 69/200\n","28/28 [==============================] - 1s 18ms/step - loss: 0.6909 - accuracy: 0.8502\n","Epoch 70/200\n","28/28 [==============================] - 0s 15ms/step - loss: 0.7049 - accuracy: 0.8409\n","Epoch 71/200\n","28/28 [==============================] - 0s 12ms/step - loss: 0.7012 - accuracy: 0.8394\n","Epoch 72/200\n","28/28 [==============================] - 0s 12ms/step - loss: 0.6897 - accuracy: 0.8495\n","Epoch 73/200\n","28/28 [==============================] - 0s 12ms/step - loss: 0.6710 - accuracy: 0.8502\n","Epoch 74/200\n","28/28 [==============================] - 0s 12ms/step - loss: 0.6927 - accuracy: 0.8430\n","Epoch 75/200\n","28/28 [==============================] - 0s 12ms/step - loss: 0.7104 - accuracy: 0.8373\n","Epoch 76/200\n","28/28 [==============================] - 0s 12ms/step - loss: 0.7381 - accuracy: 0.8244\n","Epoch 77/200\n","28/28 [==============================] - 0s 12ms/step - loss: 0.6972 - accuracy: 0.8387\n","Epoch 78/200\n","28/28 [==============================] - 0s 12ms/step - loss: 0.7722 - accuracy: 0.8201\n","Epoch 79/200\n","28/28 [==============================] - 0s 13ms/step - loss: 0.7133 - accuracy: 0.8401\n","Epoch 80/200\n","28/28 [==============================] - 0s 12ms/step - loss: 0.6774 - accuracy: 0.8459\n","Epoch 81/200\n","28/28 [==============================] - 0s 12ms/step - loss: 0.6669 - accuracy: 0.8502\n","Epoch 82/200\n","28/28 [==============================] - 0s 12ms/step - loss: 0.6637 - accuracy: 0.8516\n","Epoch 83/200\n","28/28 [==============================] - 0s 12ms/step - loss: 0.6736 - accuracy: 0.8466\n","Epoch 84/200\n","28/28 [==============================] - 0s 12ms/step - loss: 0.6687 - accuracy: 0.8459\n","Epoch 85/200\n","28/28 [==============================] - 0s 12ms/step - loss: 0.6639 - accuracy: 0.8502\n","Epoch 86/200\n","28/28 [==============================] - 0s 12ms/step - loss: 0.6761 - accuracy: 0.8430\n","Epoch 87/200\n","28/28 [==============================] - 0s 12ms/step - loss: 0.7341 - accuracy: 0.8272\n","Epoch 88/200\n","28/28 [==============================] - 0s 14ms/step - loss: 0.7329 - accuracy: 0.8244\n","Epoch 89/200\n","28/28 [==============================] - 1s 21ms/step - loss: 0.7111 - accuracy: 0.8280\n","Epoch 90/200\n","28/28 [==============================] - 0s 13ms/step - loss: 0.7073 - accuracy: 0.8294\n","Epoch 91/200\n","28/28 [==============================] - 1s 22ms/step - loss: 0.6968 - accuracy: 0.8301\n","Epoch 92/200\n","28/28 [==============================] - 0s 12ms/step - loss: 0.6807 - accuracy: 0.8294\n","Epoch 93/200\n","28/28 [==============================] - 1s 22ms/step - loss: 0.6576 - accuracy: 0.8480\n","Epoch 94/200\n","28/28 [==============================] - 0s 13ms/step - loss: 0.7516 - accuracy: 0.8172\n","Epoch 95/200\n","28/28 [==============================] - 0s 13ms/step - loss: 0.7305 - accuracy: 0.8394\n","Epoch 96/200\n","28/28 [==============================] - 0s 16ms/step - loss: 0.6702 - accuracy: 0.8459\n","Epoch 97/200\n","28/28 [==============================] - 0s 16ms/step - loss: 0.7616 - accuracy: 0.8258\n","Epoch 98/200\n","28/28 [==============================] - 0s 16ms/step - loss: 0.6801 - accuracy: 0.8394\n","Epoch 99/200\n","28/28 [==============================] - 0s 17ms/step - loss: 0.6528 - accuracy: 0.8523\n","Epoch 100/200\n","28/28 [==============================] - 0s 17ms/step - loss: 0.6418 - accuracy: 0.8523\n","Epoch 101/200\n","28/28 [==============================] - 0s 12ms/step - loss: 0.7323 - accuracy: 0.8287\n","Epoch 102/200\n","28/28 [==============================] - 0s 12ms/step - loss: 0.6557 - accuracy: 0.8459\n","Epoch 103/200\n","28/28 [==============================] - 0s 13ms/step - loss: 0.6419 - accuracy: 0.8487\n","Epoch 104/200\n","28/28 [==============================] - 0s 13ms/step - loss: 0.6459 - accuracy: 0.8530\n","Epoch 105/200\n","28/28 [==============================] - 0s 12ms/step - loss: 0.6702 - accuracy: 0.8423\n","Epoch 106/200\n","28/28 [==============================] - 0s 13ms/step - loss: 0.6974 - accuracy: 0.8323\n","Epoch 107/200\n","28/28 [==============================] - 0s 13ms/step - loss: 0.6404 - accuracy: 0.8530\n","Epoch 108/200\n","28/28 [==============================] - 0s 12ms/step - loss: 0.6325 - accuracy: 0.8509\n","Epoch 109/200\n","28/28 [==============================] - 0s 13ms/step - loss: 0.6311 - accuracy: 0.8523\n","Epoch 110/200\n","28/28 [==============================] - 0s 13ms/step - loss: 0.7443 - accuracy: 0.8222\n","Epoch 111/200\n","28/28 [==============================] - 0s 13ms/step - loss: 0.7523 - accuracy: 0.8136\n","Epoch 112/200\n","28/28 [==============================] - 0s 13ms/step - loss: 0.6919 - accuracy: 0.8351\n","Epoch 113/200\n","28/28 [==============================] - 0s 13ms/step - loss: 0.6853 - accuracy: 0.8301\n","Epoch 114/200\n","28/28 [==============================] - 0s 12ms/step - loss: 0.6675 - accuracy: 0.8351\n","Epoch 115/200\n","28/28 [==============================] - 0s 13ms/step - loss: 0.6621 - accuracy: 0.8337\n","Epoch 116/200\n","28/28 [==============================] - 0s 13ms/step - loss: 0.6524 - accuracy: 0.8344\n","Epoch 117/200\n","28/28 [==============================] - 0s 12ms/step - loss: 0.6500 - accuracy: 0.8337\n","Epoch 118/200\n","28/28 [==============================] - 0s 12ms/step - loss: 0.6475 - accuracy: 0.8409\n","Epoch 119/200\n","28/28 [==============================] - 0s 12ms/step - loss: 0.6353 - accuracy: 0.8437\n","Epoch 120/200\n","28/28 [==============================] - 0s 13ms/step - loss: 0.6320 - accuracy: 0.8516\n","Epoch 121/200\n","28/28 [==============================] - 0s 13ms/step - loss: 0.6373 - accuracy: 0.8523\n","Epoch 122/200\n","28/28 [==============================] - 0s 12ms/step - loss: 0.6169 - accuracy: 0.8552\n","Epoch 123/200\n","28/28 [==============================] - 0s 12ms/step - loss: 0.6314 - accuracy: 0.8559\n","Epoch 124/200\n","28/28 [==============================] - 0s 13ms/step - loss: 0.6285 - accuracy: 0.8538\n","Epoch 125/200\n","28/28 [==============================] - 0s 12ms/step - loss: 0.6285 - accuracy: 0.8538\n","Epoch 126/200\n","28/28 [==============================] - 0s 13ms/step - loss: 0.6363 - accuracy: 0.8509\n","Epoch 127/200\n","28/28 [==============================] - 0s 12ms/step - loss: 0.6066 - accuracy: 0.8609\n","Epoch 128/200\n","28/28 [==============================] - 0s 13ms/step - loss: 0.6035 - accuracy: 0.8588\n","Epoch 129/200\n","28/28 [==============================] - 0s 17ms/step - loss: 0.5952 - accuracy: 0.8595\n","Epoch 130/200\n","28/28 [==============================] - 0s 16ms/step - loss: 0.5911 - accuracy: 0.8624\n","Epoch 131/200\n","28/28 [==============================] - 0s 17ms/step - loss: 0.6006 - accuracy: 0.8595\n","Epoch 132/200\n","28/28 [==============================] - 0s 17ms/step - loss: 0.6000 - accuracy: 0.8631\n","Epoch 133/200\n","28/28 [==============================] - 0s 15ms/step - loss: 0.5894 - accuracy: 0.8638\n","Epoch 134/200\n","28/28 [==============================] - 0s 12ms/step - loss: 0.5978 - accuracy: 0.8638\n","Epoch 135/200\n","28/28 [==============================] - 0s 12ms/step - loss: 0.6005 - accuracy: 0.8609\n","Epoch 136/200\n","28/28 [==============================] - 0s 13ms/step - loss: 0.6163 - accuracy: 0.8588\n","Epoch 137/200\n","28/28 [==============================] - 0s 12ms/step - loss: 0.5992 - accuracy: 0.8602\n","Epoch 138/200\n","28/28 [==============================] - 0s 12ms/step - loss: 0.6045 - accuracy: 0.8588\n","Epoch 139/200\n","28/28 [==============================] - 0s 13ms/step - loss: 0.6152 - accuracy: 0.8602\n","Epoch 140/200\n","28/28 [==============================] - 0s 13ms/step - loss: 0.6489 - accuracy: 0.8416\n","Epoch 141/200\n","28/28 [==============================] - 0s 13ms/step - loss: 0.6052 - accuracy: 0.8595\n","Epoch 142/200\n","28/28 [==============================] - 0s 13ms/step - loss: 0.6117 - accuracy: 0.8559\n","Epoch 143/200\n","28/28 [==============================] - 0s 12ms/step - loss: 0.6361 - accuracy: 0.8502\n","Epoch 144/200\n","28/28 [==============================] - 0s 12ms/step - loss: 0.5950 - accuracy: 0.8638\n","Epoch 145/200\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5849 - accuracy: 0.8616\n","Epoch 146/200\n","28/28 [==============================] - 0s 12ms/step - loss: 0.5812 - accuracy: 0.8638\n","Epoch 147/200\n","28/28 [==============================] - 0s 12ms/step - loss: 0.6026 - accuracy: 0.8573\n","Epoch 148/200\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5835 - accuracy: 0.8652\n","Epoch 149/200\n","28/28 [==============================] - 0s 12ms/step - loss: 0.6066 - accuracy: 0.8588\n","Epoch 150/200\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5918 - accuracy: 0.8616\n","Epoch 151/200\n","28/28 [==============================] - 0s 12ms/step - loss: 0.5841 - accuracy: 0.8652\n","Epoch 152/200\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5783 - accuracy: 0.8667\n","Epoch 153/200\n","28/28 [==============================] - 0s 16ms/step - loss: 0.5794 - accuracy: 0.8645\n","Epoch 154/200\n","28/28 [==============================] - 0s 16ms/step - loss: 0.5799 - accuracy: 0.8638\n","Epoch 155/200\n","28/28 [==============================] - 0s 15ms/step - loss: 0.5689 - accuracy: 0.8688\n","Epoch 156/200\n","28/28 [==============================] - 0s 17ms/step - loss: 0.5712 - accuracy: 0.8638\n","Epoch 157/200\n","28/28 [==============================] - 0s 12ms/step - loss: 0.5764 - accuracy: 0.8631\n","Epoch 158/200\n","28/28 [==============================] - 1s 20ms/step - loss: 0.5642 - accuracy: 0.8688\n","Epoch 159/200\n","28/28 [==============================] - 0s 17ms/step - loss: 0.5649 - accuracy: 0.8645\n","Epoch 160/200\n","28/28 [==============================] - 0s 16ms/step - loss: 0.5654 - accuracy: 0.8667\n","Epoch 161/200\n","28/28 [==============================] - 0s 16ms/step - loss: 0.5762 - accuracy: 0.8631\n","Epoch 162/200\n","28/28 [==============================] - 0s 17ms/step - loss: 0.5502 - accuracy: 0.8674\n","Epoch 163/200\n","28/28 [==============================] - 0s 17ms/step - loss: 0.5555 - accuracy: 0.8667\n","Epoch 164/200\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5612 - accuracy: 0.8667\n","Epoch 165/200\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5514 - accuracy: 0.8674\n","Epoch 166/200\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5561 - accuracy: 0.8710\n","Epoch 167/200\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5507 - accuracy: 0.8703\n","Epoch 168/200\n","28/28 [==============================] - 0s 12ms/step - loss: 0.5424 - accuracy: 0.8710\n","Epoch 169/200\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5387 - accuracy: 0.8724\n","Epoch 170/200\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5621 - accuracy: 0.8659\n","Epoch 171/200\n","28/28 [==============================] - 0s 12ms/step - loss: 0.5539 - accuracy: 0.8659\n","Epoch 172/200\n","28/28 [==============================] - 0s 12ms/step - loss: 0.5402 - accuracy: 0.8717\n","Epoch 173/200\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5437 - accuracy: 0.8674\n","Epoch 174/200\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5503 - accuracy: 0.8652\n","Epoch 175/200\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5321 - accuracy: 0.8703\n","Epoch 176/200\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5329 - accuracy: 0.8731\n","Epoch 177/200\n","28/28 [==============================] - 0s 12ms/step - loss: 0.5202 - accuracy: 0.8760\n","Epoch 178/200\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5449 - accuracy: 0.8659\n","Epoch 179/200\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5550 - accuracy: 0.8659\n","Epoch 180/200\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5302 - accuracy: 0.8724\n","Epoch 181/200\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5149 - accuracy: 0.8789\n","Epoch 182/200\n","28/28 [==============================] - 0s 12ms/step - loss: 0.5168 - accuracy: 0.8810\n","Epoch 183/200\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5158 - accuracy: 0.8789\n","Epoch 184/200\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5148 - accuracy: 0.8781\n","Epoch 185/200\n","28/28 [==============================] - 0s 12ms/step - loss: 0.5150 - accuracy: 0.8760\n","Epoch 186/200\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5043 - accuracy: 0.8774\n","Epoch 187/200\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5027 - accuracy: 0.8817\n","Epoch 188/200\n","28/28 [==============================] - 0s 12ms/step - loss: 0.4990 - accuracy: 0.8789\n","Epoch 189/200\n","28/28 [==============================] - 0s 12ms/step - loss: 0.5156 - accuracy: 0.8746\n","Epoch 190/200\n","28/28 [==============================] - 0s 13ms/step - loss: 0.5172 - accuracy: 0.8767\n","Epoch 191/200\n","28/28 [==============================] - 0s 16ms/step - loss: 0.5108 - accuracy: 0.8781\n","Epoch 192/200\n","28/28 [==============================] - 0s 16ms/step - loss: 0.5412 - accuracy: 0.8710\n","Epoch 193/200\n","28/28 [==============================] - 0s 16ms/step - loss: 0.5198 - accuracy: 0.8753\n","Epoch 194/200\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4910 - accuracy: 0.8817\n","Epoch 195/200\n","28/28 [==============================] - 0s 17ms/step - loss: 0.4865 - accuracy: 0.8832\n","Epoch 196/200\n","28/28 [==============================] - 0s 12ms/step - loss: 0.4823 - accuracy: 0.8860\n","Epoch 197/200\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4842 - accuracy: 0.8875\n","Epoch 198/200\n","28/28 [==============================] - 0s 12ms/step - loss: 0.4878 - accuracy: 0.8803\n","Epoch 199/200\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4820 - accuracy: 0.8824\n","Epoch 200/200\n","28/28 [==============================] - 0s 13ms/step - loss: 0.4756 - accuracy: 0.8846\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.src.callbacks.History at 0x78b8adfa7a30>"]},"metadata":{},"execution_count":9}],"source":["model = deep_lstm()\n","model.fit(X_train, y_train, epochs = 200, batch_size = 50, verbose = 1)"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UdYb_vLRaOmT","executionInfo":{"status":"ok","timestamp":1712319684875,"user_tz":-330,"elapsed":1840,"user":{"displayName":"jiyaudeen Meerasa","userId":"17480471567784096893"}},"outputId":"1f723871-9906-4fe4-cafd-5deaa0c24dde"},"outputs":[{"output_type":"stream","name":"stdout","text":["19/19 [==============================] - 1s 6ms/step\n"]}],"source":["y_pred = model.predict(X_test)\n","y_test_ = np.argmax(y_pred, axis = 1)"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zUugyCXKaOmT","executionInfo":{"status":"ok","timestamp":1712319689255,"user_tz":-330,"elapsed":594,"user":{"displayName":"jiyaudeen Meerasa","userId":"17480471567784096893"}},"outputId":"61bb22a6-540e-4c7e-ea0c-f0dd60115304"},"outputs":[{"output_type":"stream","name":"stdout","text":["0.8480801335559266\n"]}],"source":["print(accuracy_score(y_actual, y_test_))"]},{"cell_type":"markdown","metadata":{"id":"HEqzWM3FaOmU"},"source":["## 2. Bidirectional RNN\n","- Bidirectional RNNs consider not only one-way influence of sequence, but also the other way\n","- Actually, they can be thought as building two separate RNNs, and merging them\\\n","<br>\n","<img src=\"http://d3kbpzbmcynnmx.cloudfront.net/wp-content/uploads/2015/09/bidirectional-rnn.png\" style=\"width: 400px\"/>\n","</br>"]},{"cell_type":"code","execution_count":12,"metadata":{"collapsed":true,"jupyter":{"outputs_hidden":true},"id":"czDYAJ-eaOmU","executionInfo":{"status":"ok","timestamp":1712319695906,"user_tz":-330,"elapsed":382,"user":{"displayName":"jiyaudeen Meerasa","userId":"17480471567784096893"}}},"outputs":[],"source":["from keras.layers import Bidirectional"]},{"cell_type":"code","execution_count":13,"metadata":{"collapsed":true,"jupyter":{"outputs_hidden":true},"id":"bGTM5B6laOmU","executionInfo":{"status":"ok","timestamp":1712319700432,"user_tz":-330,"elapsed":625,"user":{"displayName":"jiyaudeen Meerasa","userId":"17480471567784096893"}}},"outputs":[],"source":["def bidirectional_lstm():\n","    model = Sequential()\n","    model.add(Bidirectional(LSTM(20, return_sequences = False), input_shape = (49,1)))\n","    model.add(Dense(46))\n","    model.add(Activation('softmax'))\n","\n","    adam = optimizers.Adam(lr = 0.001)\n","    model.compile(loss = 'categorical_crossentropy', optimizer = adam, metrics = ['accuracy'])\n","\n","    return model"]},{"cell_type":"code","execution_count":14,"metadata":{"collapsed":true,"jupyter":{"outputs_hidden":true},"colab":{"base_uri":"https://localhost:8080/"},"id":"XLj2BwpmaOmU","executionInfo":{"status":"ok","timestamp":1712319711760,"user_tz":-330,"elapsed":8221,"user":{"displayName":"jiyaudeen Meerasa","userId":"17480471567784096893"}},"outputId":"93253c9d-e25e-4ed1-a6aa-ce700f9eae61"},"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/2\n","279/279 [==============================] - 5s 8ms/step - loss: 1.6265 - accuracy: 0.6416\n","Epoch 2/2\n","279/279 [==============================] - 2s 7ms/step - loss: 0.9837 - accuracy: 0.7412\n","CPU times: user 8.4 s, sys: 345 ms, total: 8.74 s\n","Wall time: 8.16 s\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.src.callbacks.History at 0x78b853959e70>"]},"metadata":{},"execution_count":14}],"source":["%%time\n","model = bidirectional_lstm()\n","model.fit(X_train, y_train, epochs = 2, batch_size = 5, verbose = 1)"]},{"cell_type":"markdown","source":["Epoch = passing all the data once to my network\n","batch = group of input sent at once\n","Iteration = number of time the batch of data to pass through the network to complete one epoch\n","\n","sample size =  1395\n","Epoch = 2\n","batch = 5\n","Iteration = 1395/5 = 279"],"metadata":{"id":"_nxKw9Imt7Q4"}},{"cell_type":"code","execution_count":15,"metadata":{"id":"qXsAz1r7aOmU","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1712319716187,"user_tz":-330,"elapsed":1224,"user":{"displayName":"jiyaudeen Meerasa","userId":"17480471567784096893"}},"outputId":"f8f470e9-c828-4925-fe35-0dd194ae291d"},"outputs":[{"output_type":"stream","name":"stdout","text":["19/19 [==============================] - 1s 3ms/step\n"]}],"source":["y_pred = model.predict(X_test)\n","y_test_ = np.argmax(y_pred, axis = 1)"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"0V-VpZ1BaOmU","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1712319718704,"user_tz":-330,"elapsed":366,"user":{"displayName":"jiyaudeen Meerasa","userId":"17480471567784096893"}},"outputId":"c844dbba-ac7a-43a2-a90c-1e919e995d63"},"outputs":[{"output_type":"stream","name":"stdout","text":["0.8063439065108514\n"]}],"source":["print(accuracy_score(y_actual, y_test_))"]},{"cell_type":"markdown","metadata":{"id":"exIlz26eaOmU"},"source":["## 3. Deep Bidirectional RNN\n","- Bidirectional RNNs can be stacked\n","\n","<img src=\"http://www.wildml.com/wp-content/uploads/2015/09/Screen-Shot-2015-09-16-at-2.21.51-PM-272x300.png\" style=\"width: 300px\"/>"]},{"cell_type":"code","execution_count":17,"metadata":{"collapsed":true,"jupyter":{"outputs_hidden":true},"id":"X7D3SQwBaOmU","executionInfo":{"status":"ok","timestamp":1712319724324,"user_tz":-330,"elapsed":471,"user":{"displayName":"jiyaudeen Meerasa","userId":"17480471567784096893"}}},"outputs":[],"source":["def deep_bidirectional_lstm():\n","    model = Sequential()\n","    model.add(Bidirectional(LSTM(10, return_sequences = True), input_shape = (49,1)))\n","    model.add(Bidirectional(LSTM(10, return_sequences = True)))\n","    model.add(Bidirectional(LSTM(10, return_sequences = True)))\n","    model.add(Bidirectional(LSTM(10, return_sequences = False)))\n","    model.add(Dense(46))\n","    model.add(Activation('softmax'))\n","\n","    adam = optimizers.Adam(lr = 0.001)\n","    model.compile(loss = 'categorical_crossentropy', optimizer = adam, metrics = ['accuracy'])\n","\n","    return model"]},{"cell_type":"code","execution_count":18,"metadata":{"collapsed":true,"jupyter":{"outputs_hidden":true},"colab":{"base_uri":"https://localhost:8080/"},"id":"7VpZ3kzTaOmU","outputId":"149cb776-6ef7-421f-d83c-f017847df8d2","executionInfo":{"status":"ok","timestamp":1712319882712,"user_tz":-330,"elapsed":154251,"user":{"displayName":"jiyaudeen Meerasa","userId":"17480471567784096893"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/200\n","28/28 [==============================] - 13s 23ms/step - loss: 3.5546 - accuracy: 0.5297\n","Epoch 2/200\n","28/28 [==============================] - 1s 26ms/step - loss: 2.6887 - accuracy: 0.7147\n","Epoch 3/200\n","28/28 [==============================] - 1s 30ms/step - loss: 1.7584 - accuracy: 0.7147\n","Epoch 4/200\n","28/28 [==============================] - 1s 32ms/step - loss: 1.3013 - accuracy: 0.7147\n","Epoch 5/200\n","28/28 [==============================] - 1s 22ms/step - loss: 1.2096 - accuracy: 0.7147\n","Epoch 6/200\n","28/28 [==============================] - 1s 22ms/step - loss: 1.1869 - accuracy: 0.7147\n","Epoch 7/200\n","28/28 [==============================] - 1s 22ms/step - loss: 1.1768 - accuracy: 0.7147\n","Epoch 8/200\n","28/28 [==============================] - 1s 23ms/step - loss: 1.1690 - accuracy: 0.7147\n","Epoch 9/200\n","28/28 [==============================] - 1s 22ms/step - loss: 1.1573 - accuracy: 0.7147\n","Epoch 10/200\n","28/28 [==============================] - 1s 22ms/step - loss: 1.0690 - accuracy: 0.7147\n","Epoch 11/200\n","28/28 [==============================] - 1s 22ms/step - loss: 1.0287 - accuracy: 0.7147\n","Epoch 12/200\n","28/28 [==============================] - 1s 22ms/step - loss: 0.9536 - accuracy: 0.7147\n","Epoch 13/200\n","28/28 [==============================] - 1s 22ms/step - loss: 0.9172 - accuracy: 0.7384\n","Epoch 14/200\n","28/28 [==============================] - 1s 22ms/step - loss: 0.8995 - accuracy: 0.7627\n","Epoch 15/200\n","28/28 [==============================] - 1s 22ms/step - loss: 0.8779 - accuracy: 0.7892\n","Epoch 16/200\n","28/28 [==============================] - 1s 22ms/step - loss: 0.8882 - accuracy: 0.7642\n","Epoch 17/200\n","28/28 [==============================] - 1s 22ms/step - loss: 0.9074 - accuracy: 0.7591\n","Epoch 18/200\n","28/28 [==============================] - 1s 22ms/step - loss: 0.9129 - accuracy: 0.7950\n","Epoch 19/200\n","28/28 [==============================] - 1s 22ms/step - loss: 0.8772 - accuracy: 0.7900\n","Epoch 20/200\n","28/28 [==============================] - 1s 25ms/step - loss: 0.8484 - accuracy: 0.7935\n","Epoch 21/200\n","28/28 [==============================] - 1s 30ms/step - loss: 0.8402 - accuracy: 0.7878\n","Epoch 22/200\n","28/28 [==============================] - 1s 31ms/step - loss: 0.8271 - accuracy: 0.7986\n","Epoch 23/200\n","28/28 [==============================] - 1s 24ms/step - loss: 0.8861 - accuracy: 0.7792\n","Epoch 24/200\n","28/28 [==============================] - 1s 22ms/step - loss: 0.8732 - accuracy: 0.7842\n","Epoch 25/200\n","28/28 [==============================] - 1s 22ms/step - loss: 0.8533 - accuracy: 0.7814\n","Epoch 26/200\n","28/28 [==============================] - 1s 22ms/step - loss: 0.9110 - accuracy: 0.7978\n","Epoch 27/200\n","28/28 [==============================] - 1s 22ms/step - loss: 0.8516 - accuracy: 0.8007\n","Epoch 28/200\n","28/28 [==============================] - 1s 22ms/step - loss: 0.8233 - accuracy: 0.8022\n","Epoch 29/200\n","28/28 [==============================] - 1s 22ms/step - loss: 0.8091 - accuracy: 0.7971\n","Epoch 30/200\n","28/28 [==============================] - 1s 23ms/step - loss: 0.8007 - accuracy: 0.7993\n","Epoch 31/200\n","28/28 [==============================] - 1s 22ms/step - loss: 0.7916 - accuracy: 0.8022\n","Epoch 32/200\n","28/28 [==============================] - 1s 23ms/step - loss: 0.7901 - accuracy: 0.8007\n","Epoch 33/200\n","28/28 [==============================] - 1s 23ms/step - loss: 0.7868 - accuracy: 0.7978\n","Epoch 34/200\n","28/28 [==============================] - 1s 22ms/step - loss: 0.7876 - accuracy: 0.7971\n","Epoch 35/200\n","28/28 [==============================] - 1s 22ms/step - loss: 0.7812 - accuracy: 0.7928\n","Epoch 36/200\n","28/28 [==============================] - 1s 22ms/step - loss: 0.7748 - accuracy: 0.7978\n","Epoch 37/200\n","28/28 [==============================] - 1s 23ms/step - loss: 0.7870 - accuracy: 0.7943\n","Epoch 38/200\n","28/28 [==============================] - 1s 23ms/step - loss: 0.7778 - accuracy: 0.8029\n","Epoch 39/200\n","28/28 [==============================] - 1s 31ms/step - loss: 0.7661 - accuracy: 0.8022\n","Epoch 40/200\n","28/28 [==============================] - 1s 33ms/step - loss: 0.7670 - accuracy: 0.8043\n","Epoch 41/200\n","28/28 [==============================] - 1s 24ms/step - loss: 0.7557 - accuracy: 0.8129\n","Epoch 42/200\n","28/28 [==============================] - 1s 23ms/step - loss: 0.7778 - accuracy: 0.8115\n","Epoch 43/200\n","28/28 [==============================] - 1s 22ms/step - loss: 0.7611 - accuracy: 0.8165\n","Epoch 44/200\n","28/28 [==============================] - 1s 22ms/step - loss: 0.7534 - accuracy: 0.8194\n","Epoch 45/200\n","28/28 [==============================] - 1s 24ms/step - loss: 0.7483 - accuracy: 0.8194\n","Epoch 46/200\n","28/28 [==============================] - 1s 23ms/step - loss: 0.7466 - accuracy: 0.8201\n","Epoch 47/200\n","28/28 [==============================] - 1s 22ms/step - loss: 0.7444 - accuracy: 0.8172\n","Epoch 48/200\n","28/28 [==============================] - 1s 22ms/step - loss: 0.7491 - accuracy: 0.8194\n","Epoch 49/200\n","28/28 [==============================] - 1s 25ms/step - loss: 0.7869 - accuracy: 0.8043\n","Epoch 50/200\n","28/28 [==============================] - 1s 23ms/step - loss: 0.7641 - accuracy: 0.8050\n","Epoch 51/200\n","28/28 [==============================] - 1s 22ms/step - loss: 0.7462 - accuracy: 0.8165\n","Epoch 52/200\n","28/28 [==============================] - 1s 23ms/step - loss: 0.7398 - accuracy: 0.8194\n","Epoch 53/200\n","28/28 [==============================] - 1s 23ms/step - loss: 0.7337 - accuracy: 0.8201\n","Epoch 54/200\n","28/28 [==============================] - 1s 24ms/step - loss: 0.7307 - accuracy: 0.8237\n","Epoch 55/200\n","28/28 [==============================] - 1s 23ms/step - loss: 0.7279 - accuracy: 0.8237\n","Epoch 56/200\n","28/28 [==============================] - 1s 27ms/step - loss: 0.7333 - accuracy: 0.8179\n","Epoch 57/200\n","28/28 [==============================] - 1s 31ms/step - loss: 0.7267 - accuracy: 0.8194\n","Epoch 58/200\n","28/28 [==============================] - 1s 32ms/step - loss: 0.7267 - accuracy: 0.8194\n","Epoch 59/200\n","28/28 [==============================] - 1s 22ms/step - loss: 0.7249 - accuracy: 0.8208\n","Epoch 60/200\n","28/28 [==============================] - 1s 23ms/step - loss: 0.7227 - accuracy: 0.8237\n","Epoch 61/200\n","28/28 [==============================] - 1s 22ms/step - loss: 0.7177 - accuracy: 0.8229\n","Epoch 62/200\n","28/28 [==============================] - 1s 23ms/step - loss: 0.7328 - accuracy: 0.8122\n","Epoch 63/200\n","28/28 [==============================] - 1s 23ms/step - loss: 0.7304 - accuracy: 0.8122\n","Epoch 64/200\n","28/28 [==============================] - 1s 23ms/step - loss: 0.7176 - accuracy: 0.8186\n","Epoch 65/200\n","28/28 [==============================] - 1s 22ms/step - loss: 0.7153 - accuracy: 0.8201\n","Epoch 66/200\n","28/28 [==============================] - 1s 22ms/step - loss: 0.7195 - accuracy: 0.8244\n","Epoch 67/200\n","28/28 [==============================] - 1s 23ms/step - loss: 0.7130 - accuracy: 0.8222\n","Epoch 68/200\n","28/28 [==============================] - 1s 23ms/step - loss: 0.7117 - accuracy: 0.8229\n","Epoch 69/200\n","28/28 [==============================] - 1s 22ms/step - loss: 0.7098 - accuracy: 0.8208\n","Epoch 70/200\n","28/28 [==============================] - 1s 22ms/step - loss: 0.7141 - accuracy: 0.8165\n","Epoch 71/200\n","28/28 [==============================] - 1s 22ms/step - loss: 0.7104 - accuracy: 0.8215\n","Epoch 72/200\n","28/28 [==============================] - 1s 22ms/step - loss: 0.7045 - accuracy: 0.8244\n","Epoch 73/200\n","28/28 [==============================] - 1s 22ms/step - loss: 0.7038 - accuracy: 0.8265\n","Epoch 74/200\n","28/28 [==============================] - 1s 26ms/step - loss: 0.7103 - accuracy: 0.8201\n","Epoch 75/200\n","28/28 [==============================] - 1s 31ms/step - loss: 0.7038 - accuracy: 0.8201\n","Epoch 76/200\n","28/28 [==============================] - 1s 33ms/step - loss: 0.7123 - accuracy: 0.8215\n","Epoch 77/200\n","28/28 [==============================] - 1s 22ms/step - loss: 0.7035 - accuracy: 0.8237\n","Epoch 78/200\n","28/28 [==============================] - 1s 22ms/step - loss: 0.7008 - accuracy: 0.8265\n","Epoch 79/200\n","28/28 [==============================] - 1s 22ms/step - loss: 0.7105 - accuracy: 0.8115\n","Epoch 80/200\n","28/28 [==============================] - 1s 22ms/step - loss: 0.7146 - accuracy: 0.8194\n","Epoch 81/200\n","28/28 [==============================] - 1s 22ms/step - loss: 0.6982 - accuracy: 0.8194\n","Epoch 82/200\n","28/28 [==============================] - 1s 22ms/step - loss: 0.6953 - accuracy: 0.8151\n","Epoch 83/200\n","28/28 [==============================] - 1s 23ms/step - loss: 0.6885 - accuracy: 0.8186\n","Epoch 84/200\n","28/28 [==============================] - 1s 22ms/step - loss: 0.6985 - accuracy: 0.8201\n","Epoch 85/200\n","28/28 [==============================] - 1s 23ms/step - loss: 0.6790 - accuracy: 0.8194\n","Epoch 86/200\n","28/28 [==============================] - 1s 21ms/step - loss: 0.6900 - accuracy: 0.8172\n","Epoch 87/200\n","28/28 [==============================] - 1s 23ms/step - loss: 0.7038 - accuracy: 0.8229\n","Epoch 88/200\n","28/28 [==============================] - 1s 23ms/step - loss: 0.7336 - accuracy: 0.8165\n","Epoch 89/200\n","28/28 [==============================] - 1s 22ms/step - loss: 0.7173 - accuracy: 0.8115\n","Epoch 90/200\n","28/28 [==============================] - 1s 23ms/step - loss: 0.7038 - accuracy: 0.8186\n","Epoch 91/200\n","28/28 [==============================] - 1s 22ms/step - loss: 0.7193 - accuracy: 0.8129\n","Epoch 92/200\n","28/28 [==============================] - 1s 26ms/step - loss: 0.6909 - accuracy: 0.8201\n","Epoch 93/200\n","28/28 [==============================] - 1s 30ms/step - loss: 0.6761 - accuracy: 0.8251\n","Epoch 94/200\n","28/28 [==============================] - 1s 33ms/step - loss: 0.6743 - accuracy: 0.8237\n","Epoch 95/200\n","28/28 [==============================] - 1s 22ms/step - loss: 0.6797 - accuracy: 0.8222\n","Epoch 96/200\n","28/28 [==============================] - 1s 22ms/step - loss: 0.6885 - accuracy: 0.8222\n","Epoch 97/200\n","28/28 [==============================] - 1s 23ms/step - loss: 0.6797 - accuracy: 0.8294\n","Epoch 98/200\n","28/28 [==============================] - 1s 23ms/step - loss: 0.6931 - accuracy: 0.8179\n","Epoch 99/200\n","28/28 [==============================] - 1s 24ms/step - loss: 0.6794 - accuracy: 0.8215\n","Epoch 100/200\n","28/28 [==============================] - 1s 22ms/step - loss: 0.6719 - accuracy: 0.8237\n","Epoch 101/200\n","28/28 [==============================] - 1s 22ms/step - loss: 0.6712 - accuracy: 0.8244\n","Epoch 102/200\n","28/28 [==============================] - 1s 23ms/step - loss: 0.6925 - accuracy: 0.8208\n","Epoch 103/200\n","28/28 [==============================] - 1s 22ms/step - loss: 0.6825 - accuracy: 0.8208\n","Epoch 104/200\n","28/28 [==============================] - 1s 23ms/step - loss: 0.6761 - accuracy: 0.8258\n","Epoch 105/200\n","28/28 [==============================] - 1s 22ms/step - loss: 0.6720 - accuracy: 0.8272\n","Epoch 106/200\n","28/28 [==============================] - 1s 23ms/step - loss: 0.6762 - accuracy: 0.8194\n","Epoch 107/200\n","28/28 [==============================] - 1s 22ms/step - loss: 0.6783 - accuracy: 0.8265\n","Epoch 108/200\n","28/28 [==============================] - 1s 22ms/step - loss: 0.7179 - accuracy: 0.8179\n","Epoch 109/200\n","28/28 [==============================] - 1s 22ms/step - loss: 0.6859 - accuracy: 0.8244\n","Epoch 110/200\n","28/28 [==============================] - 1s 27ms/step - loss: 0.6750 - accuracy: 0.8308\n","Epoch 111/200\n","28/28 [==============================] - 1s 32ms/step - loss: 0.6671 - accuracy: 0.8258\n","Epoch 112/200\n","28/28 [==============================] - 1s 32ms/step - loss: 0.6604 - accuracy: 0.8287\n","Epoch 113/200\n","28/28 [==============================] - 1s 22ms/step - loss: 0.6554 - accuracy: 0.8237\n","Epoch 114/200\n","28/28 [==============================] - 1s 22ms/step - loss: 0.6526 - accuracy: 0.8244\n","Epoch 115/200\n","28/28 [==============================] - 1s 22ms/step - loss: 0.6574 - accuracy: 0.8251\n","Epoch 116/200\n","28/28 [==============================] - 1s 22ms/step - loss: 0.6480 - accuracy: 0.8251\n","Epoch 117/200\n","28/28 [==============================] - 1s 23ms/step - loss: 0.6559 - accuracy: 0.8258\n","Epoch 118/200\n","28/28 [==============================] - 1s 22ms/step - loss: 0.6682 - accuracy: 0.8294\n","Epoch 119/200\n","28/28 [==============================] - 1s 23ms/step - loss: 0.6506 - accuracy: 0.8265\n","Epoch 120/200\n","28/28 [==============================] - 1s 22ms/step - loss: 0.6528 - accuracy: 0.8237\n","Epoch 121/200\n","28/28 [==============================] - 1s 22ms/step - loss: 0.6429 - accuracy: 0.8280\n","Epoch 122/200\n","28/28 [==============================] - 1s 23ms/step - loss: 0.6407 - accuracy: 0.8258\n","Epoch 123/200\n","28/28 [==============================] - 1s 23ms/step - loss: 0.6535 - accuracy: 0.8244\n","Epoch 124/200\n","28/28 [==============================] - 1s 23ms/step - loss: 0.6484 - accuracy: 0.8272\n","Epoch 125/200\n","28/28 [==============================] - 1s 23ms/step - loss: 0.6433 - accuracy: 0.8265\n","Epoch 126/200\n","28/28 [==============================] - 1s 23ms/step - loss: 0.6527 - accuracy: 0.8244\n","Epoch 127/200\n","28/28 [==============================] - 1s 22ms/step - loss: 0.6433 - accuracy: 0.8315\n","Epoch 128/200\n","28/28 [==============================] - 1s 27ms/step - loss: 0.6436 - accuracy: 0.8280\n","Epoch 129/200\n","28/28 [==============================] - 1s 32ms/step - loss: 0.6539 - accuracy: 0.8251\n","Epoch 130/200\n","28/28 [==============================] - 1s 32ms/step - loss: 0.6352 - accuracy: 0.8323\n","Epoch 131/200\n","28/28 [==============================] - 1s 23ms/step - loss: 0.6314 - accuracy: 0.8301\n","Epoch 132/200\n","28/28 [==============================] - 1s 23ms/step - loss: 0.6332 - accuracy: 0.8308\n","Epoch 133/200\n","28/28 [==============================] - 1s 22ms/step - loss: 0.6289 - accuracy: 0.8308\n","Epoch 134/200\n","28/28 [==============================] - 1s 22ms/step - loss: 0.6291 - accuracy: 0.8337\n","Epoch 135/200\n","28/28 [==============================] - 1s 22ms/step - loss: 0.6329 - accuracy: 0.8308\n","Epoch 136/200\n","28/28 [==============================] - 1s 23ms/step - loss: 0.6498 - accuracy: 0.8258\n","Epoch 137/200\n","28/28 [==============================] - 1s 23ms/step - loss: 0.6773 - accuracy: 0.8280\n","Epoch 138/200\n","28/28 [==============================] - 1s 22ms/step - loss: 0.6277 - accuracy: 0.8308\n","Epoch 139/200\n","28/28 [==============================] - 1s 23ms/step - loss: 0.6222 - accuracy: 0.8323\n","Epoch 140/200\n","28/28 [==============================] - 1s 23ms/step - loss: 0.6153 - accuracy: 0.8330\n","Epoch 141/200\n","28/28 [==============================] - 1s 23ms/step - loss: 0.6199 - accuracy: 0.8337\n","Epoch 142/200\n","28/28 [==============================] - 1s 22ms/step - loss: 0.6254 - accuracy: 0.8323\n","Epoch 143/200\n","28/28 [==============================] - 1s 22ms/step - loss: 0.6284 - accuracy: 0.8308\n","Epoch 144/200\n","28/28 [==============================] - 1s 23ms/step - loss: 0.6190 - accuracy: 0.8351\n","Epoch 145/200\n","28/28 [==============================] - 1s 23ms/step - loss: 0.6105 - accuracy: 0.8344\n","Epoch 146/200\n","28/28 [==============================] - 1s 28ms/step - loss: 0.6195 - accuracy: 0.8280\n","Epoch 147/200\n","28/28 [==============================] - 1s 31ms/step - loss: 0.6195 - accuracy: 0.8294\n","Epoch 148/200\n","28/28 [==============================] - 1s 31ms/step - loss: 0.6140 - accuracy: 0.8337\n","Epoch 149/200\n","28/28 [==============================] - 1s 23ms/step - loss: 0.6082 - accuracy: 0.8351\n","Epoch 150/200\n","28/28 [==============================] - 1s 22ms/step - loss: 0.6014 - accuracy: 0.8358\n","Epoch 151/200\n","28/28 [==============================] - 1s 23ms/step - loss: 0.6218 - accuracy: 0.8344\n","Epoch 152/200\n","28/28 [==============================] - 1s 23ms/step - loss: 0.6107 - accuracy: 0.8323\n","Epoch 153/200\n","28/28 [==============================] - 1s 22ms/step - loss: 0.6326 - accuracy: 0.8315\n","Epoch 154/200\n","28/28 [==============================] - 1s 24ms/step - loss: 0.7216 - accuracy: 0.8229\n","Epoch 155/200\n","28/28 [==============================] - 1s 23ms/step - loss: 0.6585 - accuracy: 0.8280\n","Epoch 156/200\n","28/28 [==============================] - 1s 22ms/step - loss: 0.6230 - accuracy: 0.8272\n","Epoch 157/200\n","28/28 [==============================] - 1s 23ms/step - loss: 0.6150 - accuracy: 0.8344\n","Epoch 158/200\n","28/28 [==============================] - 1s 22ms/step - loss: 0.6235 - accuracy: 0.8366\n","Epoch 159/200\n","28/28 [==============================] - 1s 23ms/step - loss: 0.6047 - accuracy: 0.8337\n","Epoch 160/200\n","28/28 [==============================] - 1s 23ms/step - loss: 0.6020 - accuracy: 0.8358\n","Epoch 161/200\n","28/28 [==============================] - 1s 23ms/step - loss: 0.6255 - accuracy: 0.8301\n","Epoch 162/200\n","28/28 [==============================] - 1s 24ms/step - loss: 0.6130 - accuracy: 0.8301\n","Epoch 163/200\n","28/28 [==============================] - 1s 23ms/step - loss: 0.6046 - accuracy: 0.8323\n","Epoch 164/200\n","28/28 [==============================] - 1s 31ms/step - loss: 0.6137 - accuracy: 0.8323\n","Epoch 165/200\n","28/28 [==============================] - 1s 32ms/step - loss: 0.6080 - accuracy: 0.8308\n","Epoch 166/200\n","28/28 [==============================] - 1s 27ms/step - loss: 0.5925 - accuracy: 0.8394\n","Epoch 167/200\n","28/28 [==============================] - 1s 23ms/step - loss: 0.6016 - accuracy: 0.8387\n","Epoch 168/200\n","28/28 [==============================] - 1s 23ms/step - loss: 0.6017 - accuracy: 0.8366\n","Epoch 169/200\n","28/28 [==============================] - 1s 24ms/step - loss: 0.6012 - accuracy: 0.8358\n","Epoch 170/200\n","28/28 [==============================] - 1s 23ms/step - loss: 0.5910 - accuracy: 0.8344\n","Epoch 171/200\n","28/28 [==============================] - 1s 22ms/step - loss: 0.5953 - accuracy: 0.8330\n","Epoch 172/200\n","28/28 [==============================] - 1s 22ms/step - loss: 0.5861 - accuracy: 0.8401\n","Epoch 173/200\n","28/28 [==============================] - 1s 22ms/step - loss: 0.5899 - accuracy: 0.8394\n","Epoch 174/200\n","28/28 [==============================] - 1s 23ms/step - loss: 0.5934 - accuracy: 0.8323\n","Epoch 175/200\n","28/28 [==============================] - 1s 23ms/step - loss: 0.5920 - accuracy: 0.8358\n","Epoch 176/200\n","28/28 [==============================] - 1s 23ms/step - loss: 0.5734 - accuracy: 0.8416\n","Epoch 177/200\n","28/28 [==============================] - 1s 23ms/step - loss: 0.5786 - accuracy: 0.8380\n","Epoch 178/200\n","28/28 [==============================] - 1s 23ms/step - loss: 0.5735 - accuracy: 0.8430\n","Epoch 179/200\n","28/28 [==============================] - 1s 23ms/step - loss: 0.6030 - accuracy: 0.8330\n","Epoch 180/200\n","28/28 [==============================] - 1s 23ms/step - loss: 0.5998 - accuracy: 0.8358\n","Epoch 181/200\n","28/28 [==============================] - 1s 24ms/step - loss: 0.6231 - accuracy: 0.8287\n","Epoch 182/200\n","28/28 [==============================] - 1s 31ms/step - loss: 0.6426 - accuracy: 0.8265\n","Epoch 183/200\n","28/28 [==============================] - 1s 33ms/step - loss: 0.7165 - accuracy: 0.8179\n","Epoch 184/200\n","28/28 [==============================] - 1s 24ms/step - loss: 0.6067 - accuracy: 0.8301\n","Epoch 185/200\n","28/28 [==============================] - 1s 22ms/step - loss: 0.5926 - accuracy: 0.8373\n","Epoch 186/200\n","28/28 [==============================] - 1s 22ms/step - loss: 0.5845 - accuracy: 0.8366\n","Epoch 187/200\n","28/28 [==============================] - 1s 22ms/step - loss: 0.6008 - accuracy: 0.8358\n","Epoch 188/200\n","28/28 [==============================] - 1s 23ms/step - loss: 0.5936 - accuracy: 0.8358\n","Epoch 189/200\n","28/28 [==============================] - 1s 25ms/step - loss: 0.5846 - accuracy: 0.8394\n","Epoch 190/200\n","28/28 [==============================] - 1s 23ms/step - loss: 0.5803 - accuracy: 0.8380\n","Epoch 191/200\n","28/28 [==============================] - 1s 22ms/step - loss: 0.5856 - accuracy: 0.8394\n","Epoch 192/200\n","28/28 [==============================] - 1s 23ms/step - loss: 0.6071 - accuracy: 0.8366\n","Epoch 193/200\n","28/28 [==============================] - 1s 23ms/step - loss: 0.5892 - accuracy: 0.8366\n","Epoch 194/200\n","28/28 [==============================] - 1s 23ms/step - loss: 0.5735 - accuracy: 0.8423\n","Epoch 195/200\n","28/28 [==============================] - 1s 22ms/step - loss: 0.5678 - accuracy: 0.8416\n","Epoch 196/200\n","28/28 [==============================] - 1s 22ms/step - loss: 0.5730 - accuracy: 0.8401\n","Epoch 197/200\n","28/28 [==============================] - 1s 23ms/step - loss: 0.5884 - accuracy: 0.8330\n","Epoch 198/200\n","28/28 [==============================] - 1s 23ms/step - loss: 0.5938 - accuracy: 0.8351\n","Epoch 199/200\n","28/28 [==============================] - 1s 27ms/step - loss: 0.5835 - accuracy: 0.8387\n","Epoch 200/200\n","28/28 [==============================] - 1s 31ms/step - loss: 0.6186 - accuracy: 0.8315\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.src.callbacks.History at 0x78b832a62230>"]},"metadata":{},"execution_count":18}],"source":["model = deep_bidirectional_lstm()\n","model.fit(X_train, y_train, epochs = 200, batch_size = 50, verbose = 1)"]},{"cell_type":"code","execution_count":19,"metadata":{"id":"obtE4RJtaOmU","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1712319887216,"user_tz":-330,"elapsed":2868,"user":{"displayName":"jiyaudeen Meerasa","userId":"17480471567784096893"}},"outputId":"8265772b-2ed7-423a-c4ca-d8bcae946fcc"},"outputs":[{"output_type":"stream","name":"stdout","text":["19/19 [==============================] - 2s 10ms/step\n"]}],"source":["y_pred = model.predict(X_test)\n","y_test_ = np.argmax(y_pred, axis = 1)"]},{"cell_type":"code","execution_count":20,"metadata":{"id":"2HhK30ARaOmU","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1712319890553,"user_tz":-330,"elapsed":369,"user":{"displayName":"jiyaudeen Meerasa","userId":"17480471567784096893"}},"outputId":"28c13ed6-2192-4e30-f612-9bf19a6b1f8e"},"outputs":[{"output_type":"stream","name":"stdout","text":["0.8063439065108514\n"]}],"source":["print(accuracy_score(y_actual, y_test_))"]},{"cell_type":"code","source":[],"metadata":{"id":"IonyLVdAgQ3F"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["1. SimpleRNN\n","2. Stacked RNN\n","3. LSTM\n","4. Stacked LSTM\n","5. Bidirectional LSTM\n","6. Stacked Bidirectional LSTM"],"metadata":{"id":"-jkPIa3Jqlld"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"dvK-JsVbrQ12"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"QnowXElprQ9e"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UHRlCF7urRQM"},"source":["## Bidirectional GRU\n"]},{"cell_type":"code","execution_count":21,"metadata":{"collapsed":true,"jupyter":{"outputs_hidden":true},"id":"CLJQmScnrRQM","executionInfo":{"status":"ok","timestamp":1712320058527,"user_tz":-330,"elapsed":382,"user":{"displayName":"jiyaudeen Meerasa","userId":"17480471567784096893"}}},"outputs":[],"source":["from keras.layers import Bidirectional"]},{"cell_type":"code","execution_count":22,"metadata":{"collapsed":true,"jupyter":{"outputs_hidden":true},"id":"4NAEfGhRrRQM","executionInfo":{"status":"ok","timestamp":1712320060616,"user_tz":-330,"elapsed":479,"user":{"displayName":"jiyaudeen Meerasa","userId":"17480471567784096893"}}},"outputs":[],"source":["def bidirectional_gru():\n","    model = Sequential()\n","    model.add(Bidirectional(GRU(20, return_sequences = False), input_shape = (49,1)))\n","    model.add(Dense(46))\n","    model.add(Activation('softmax'))\n","\n","    adam = optimizers.Adam()\n","    model.compile(loss = 'categorical_crossentropy', optimizer = adam, metrics = ['accuracy'])\n","\n","    return model"]},{"cell_type":"code","execution_count":23,"metadata":{"collapsed":true,"jupyter":{"outputs_hidden":true},"id":"HGPtXTtXrRQM","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1712320071895,"user_tz":-330,"elapsed":7872,"user":{"displayName":"jiyaudeen Meerasa","userId":"17480471567784096893"}},"outputId":"5e074c13-c505-430f-cdd8-058e89aba44b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/2\n","279/279 [==============================] - 5s 9ms/step - loss: 1.6129 - accuracy: 0.6452\n","Epoch 2/2\n","279/279 [==============================] - 2s 7ms/step - loss: 1.0838 - accuracy: 0.7133\n","CPU times: user 7.85 s, sys: 371 ms, total: 8.22 s\n","Wall time: 7.75 s\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.src.callbacks.History at 0x78b833bf92d0>"]},"metadata":{},"execution_count":23}],"source":["%%time\n","model = bidirectional_gru()\n","model.fit(X_train, y_train, epochs = 2, batch_size = 5, verbose = 1)"]},{"cell_type":"code","execution_count":24,"metadata":{"id":"HtCy2f_TrRQM","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1712320074740,"user_tz":-330,"elapsed":938,"user":{"displayName":"jiyaudeen Meerasa","userId":"17480471567784096893"}},"outputId":"38bc7491-b5e0-44b5-ef1e-277a92993d41"},"outputs":[{"output_type":"stream","name":"stdout","text":["19/19 [==============================] - 1s 5ms/step\n"]}],"source":["y_pred = model.predict(X_test)\n","y_test_ = np.argmax(y_pred, axis = 1)"]},{"cell_type":"code","execution_count":25,"metadata":{"id":"yYWVxc_trRQM","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1712320076729,"user_tz":-330,"elapsed":385,"user":{"displayName":"jiyaudeen Meerasa","userId":"17480471567784096893"}},"outputId":"cb33e07f-fd06-4be1-cc6c-8c68c0cd282b"},"outputs":[{"output_type":"stream","name":"stdout","text":["0.7646076794657763\n"]}],"source":["print(accuracy_score(y_actual, y_test_))"]},{"cell_type":"code","source":[],"metadata":{"id":"JWlZ3wlHsV4B"},"execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.6"},"colab":{"provenance":[],"gpuType":"T4","toc_visible":true},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}